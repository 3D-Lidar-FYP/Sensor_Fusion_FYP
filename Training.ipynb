{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3D-Lidar-FYP/Sensor_Fusion_FYP/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBAG1DiNSFI7"
      },
      "source": [
        "!pip install keras==2.1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AHoNgtmSJCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100b2fbe-1dff-42cc-9db1-e1733ac83b48"
      },
      "source": [
        "%tensorflow_version 1.x "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXjqd36-4pbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365a923f-160d-49c8-b29f-a401f8398d43"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Add, concatenate\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten, Reshape, Dropout\n",
        "from keras.layers import Convolution1D, MaxPooling1D, BatchNormalization\n",
        "from keras.layers import Lambda\n",
        "from keras.utils import np_utils\n",
        "import h5py\n",
        "from matplotlib.pyplot import imshow\n",
        "import glob\n",
        "import math\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGKXXpvE7Q2N",
        "outputId": "420eecdd-c2fc-4a14-ac2f-191f228d422c"
      },
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 160983 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.24-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.24-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.24-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "zRUMrPMU7U-G"
      },
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dS1FPqzASzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2612344d-c05a-4fbe-ed3e-64e003b6516d"
      },
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8KbaU_fz8gas"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Xnl59Q6CAlFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce45f28d-ebeb-479c-f114-1160cb9a56dc"
      },
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print ('Files in Drive:')\n",
        "!ls drive/Colab\\ Notebooks\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in Drive:\n",
            "'Copy of Welcome To Colaboratory'    train_points.npy\n",
            "'Data Processing (bdb373c6).ipynb'   Untitled0.ipynb\n",
            "'Data Processing.ipynb'\t\t     Untitled10.ipynb\n",
            " Evaluation.ipynb\t\t     Untitled1.ipynb\n",
            " intermediate_output.npy\t     Untitled2.ipynb\n",
            " my_model_weights_450.h5\t     Untitled3.ipynb\n",
            " processed_image.npy\t\t     Untitled4.ipynb\n",
            " train_classes.npy\t\t     Untitled5.ipynb\n",
            " trainHistoryDict_history450\t     Untitled6.ipynb\n",
            " Training.ipynb\t\t\t     Untitled8.ipynb\n",
            " train_labels.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PIU1JB7f7qEC"
      },
      "source": [
        "points =  np.load('drive/Colab Notebooks/train_points.npy')\n",
        "labels = np.load('drive/Colab Notebooks/train_labels.npy')\n",
        "#labels = labels.reshape((7481,24))\n",
        "labels = labels.reshape((5401,24))\n",
        "classes = np.load('drive/Colab Notebooks/train_classes.npy')\n",
        "classesNP= classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_J1q5rB_PO8",
        "outputId": "08ec2ef4-385c-48ba-dd0e-64cb0fdfc6ac"
      },
      "source": [
        "#intermediate_output = np.load('drive/Colab Notebooks/processed_image.npy') #I had written this\n",
        "intermediate_output = np.load('drive/Colab Notebooks/intermediate_output.npy')\n",
        "intermediate_output = np.squeeze(intermediate_output)\n",
        "print(intermediate_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5402, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxr3C7DsvnY4"
      },
      "source": [
        "Model Definition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcT9YQlSA4Po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10c8f93-14ed-4b1e-c2f0-ca48acc0a82e"
      },
      "source": [
        "\n",
        "def mat_mul(A, B):\n",
        "    return tf.matmul(A, B)\n",
        "\n",
        "# number of points in each sample\n",
        "num_points = 2048\n",
        "\n",
        "# number of categories\n",
        "k = 3\n",
        "\n",
        "# define optimizer\n",
        "adam = optimizers.Adam(lr=0.001, decay=0.7)\n",
        "\n",
        "# ------------------------------------ Pointnet Architecture\n",
        "# input_Transformation_net\n",
        "input_points = Input(shape=(num_points, 3))\n",
        "x = Convolution1D(64, 1, activation='relu',\n",
        "                  input_shape=(num_points, 3))(input_points)\n",
        "#x = BatchNormalization()(x)\n",
        "x = Convolution1D(128, 1, activation='relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "x = Convolution1D(1024, 1, activation='relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=num_points)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
        "input_T = Reshape((3, 3))(x)\n",
        "\n",
        "# forward net\n",
        "g = Lambda(mat_mul, arguments={'B': input_T})(input_points)\n",
        "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
        "#g = BatchNormalization()(g)\n",
        "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
        "#g = BatchNormalization()(g)\n",
        "\n",
        "# feature transform net\n",
        "f = Convolution1D(64, 1, activation='relu')(g)\n",
        "#f = BatchNormalization()(f)\n",
        "f = Convolution1D(128, 1, activation='relu')(f)\n",
        "#f = BatchNormalization()(f)\n",
        "f = Convolution1D(1024, 1, activation='relu')(f)\n",
        "#f = BatchNormalization()(f)\n",
        "f = MaxPooling1D(pool_size=num_points)(f)\n",
        "f = Dense(512, activation='relu')(f)\n",
        "#f = BatchNormalization()(f)\n",
        "f = Dense(256, activation='relu')(f)\n",
        "#f = BatchNormalization()(f)\n",
        "f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
        "feature_T = Reshape((64, 64))(f)\n",
        "\n",
        "# forward net\n",
        "g = Lambda(mat_mul, arguments={'B': feature_T})(g)\n",
        "g = Convolution1D(64, 1, activation='relu')(g)\n",
        "#g = BatchNormalization()(g)\n",
        "g = Convolution1D(128, 1, activation='relu')(g)\n",
        "#g = BatchNormalization()(g)\n",
        "g = Convolution1D(1024, 1, activation='relu')(g)\n",
        "#g = BatchNormalization()(g)\n",
        "\n",
        "# global_feature\n",
        "global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
        "global_feature = Flatten()(global_feature)\n",
        "# point_net_cls\n",
        "#c = Dense(512, activation='relu')(global_feature)\n",
        "#c = BatchNormalization()(c)\n",
        "#c = Dropout(rate=0.7)(c)\n",
        "#c = Dense(256, activation='relu')(c)\n",
        "#c = BatchNormalization()(c)\n",
        "#c = Dropout(rate=0.7)(c)\n",
        "#c = Dense(k, activation='softmax')(c)\n",
        "#prediction = Flatten()(c)\n",
        "# --------------------------------------------------end of pointnet\n",
        "\n",
        "#Fusion\n",
        "\n",
        "resnet_activation = Input(shape=(intermediate_output.shape[1],), name='intermediate_output')\n",
        "#resnet_activation = Input(shape=intermediate_output.shape, name='intermediate_output') #I had written this\n",
        "f = Concatenate()([global_feature, resnet_activation])\n",
        "\n",
        "#Definition of MLP Layer\n",
        "f = Dense(512, activation='relu')(f)\n",
        "f = Dense(128, activation='relu')(f)\n",
        "f = Dense(128, activation='relu')(f)\n",
        "boxes = Dense(labels.shape[-1])(f)\n",
        "classes = Dense(classes.shape[-1],activation ='sigmoid')(f)\n",
        "\n",
        "\n",
        "# print the model summary\n",
        "model = Model(inputs=[input_points, resnet_activation], outputs=[boxes, classes])\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 2048, 3)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2048, 3)      0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 2048, 64)     256         lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 2048, 64)     4160        conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 2048, 64)     0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 2048, 64)     4160        lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 2048, 128)    8320        conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 2048, 1024)   132096      conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 1, 1024)      0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1024)         0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "intermediate_output (InputLayer (None, 1000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2024)         0           flatten_1[0][0]                  \n",
            "                                                                 intermediate_output[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 512)          1036800     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          65664       dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 128)          16512       dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 24)           3096        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 3)            387         dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,271,451\n",
            "Trainable params: 1,271,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fllaj_SJvnY5"
      },
      "source": [
        "Load Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgj7I88gBf6_"
      },
      "source": [
        "#skipping this block for now\n",
        "index = np.load('permuted_indices.npy')\n",
        "\n",
        "train_points = points[index[0:6750]]\n",
        "dev_points = points[index[6750:7115]]\n",
        "test_points = points[index[7115:]]\n",
        "\n",
        "train_classes = classes[index[0:6750]]\n",
        "dev_classes = classes[index[6750:7115]]\n",
        "test_classes = classes[index[7115:]]\n",
        "\n",
        "train_labels = labels[index[0:6750]]\n",
        "dev_labels = labels[index[6750:7115]]\n",
        "test_labels = labels[index[7115:]]\n",
        "\n",
        "train_intermediate = intermediate_output[index[0:6750]]\n",
        "dev_intermediate = intermediate_output[index[6750:7115]]\n",
        "test_intermediate = intermediate_output[index[7115:]]\n",
        "\n",
        "print(train_points.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_classes.shape)\n",
        "print(train_intermediate.shape)\n",
        "\n",
        "print(dev_points.shape)\n",
        "print(dev_labels.shape)\n",
        "print(dev_classes.shape)\n",
        "print(dev_intermediate.shape)\n",
        "\n",
        "print(test_points.shape)\n",
        "print(test_labels.shape)\n",
        "print(test_classes.shape)\n",
        "print(test_intermediate.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEvTg_WCTAnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03391b37-cc64-4a61-b894-a55112219f83"
      },
      "source": [
        "# I wrote this\n",
        "train_points = points[0:4000]\n",
        "dev_points = points[4000:5000]\n",
        "test_points = points[5000:5401]\n",
        "\n",
        "train_classes = classesNP[0:4000]\n",
        "dev_classes = classesNP[4000:5000]\n",
        "test_classes = classesNP[5000:5401]\n",
        "\n",
        "train_labels = labels[0:4000]\n",
        "dev_labels = labels[4000:5000]\n",
        "test_labels = labels[5000:5401]\n",
        "\n",
        "train_intermediate = intermediate_output[0:4000]\n",
        "dev_intermediate = intermediate_output[4000:5000]\n",
        "test_intermediate = intermediate_output[5000:5401]\n",
        "\n",
        "print(train_points.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_classes.shape)\n",
        "print(train_intermediate.shape)\n",
        "\n",
        "print(dev_points.shape)\n",
        "print(dev_labels.shape)\n",
        "print(dev_classes.shape)\n",
        "print(dev_intermediate.shape)\n",
        "\n",
        "print(test_points.shape)\n",
        "print(test_labels.shape)\n",
        "print(test_classes.shape)\n",
        "print(test_intermediate.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 2048, 3)\n",
            "(4000, 24)\n",
            "(4000, 3)\n",
            "(4000, 1000)\n",
            "(1000, 2048, 3)\n",
            "(1000, 24)\n",
            "(1000, 3)\n",
            "(1000, 1000)\n",
            "(401, 2048, 3)\n",
            "(401, 24)\n",
            "(401, 3)\n",
            "(401, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc-5t6DMvnY6"
      },
      "source": [
        "Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ol7vT41PBkUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970a2e4d-3a92-452b-e616-1cf5385fd1f7"
      },
      "source": [
        "HUBER_DELTA = 0.5\n",
        "def smoothL1(y_true, y_pred):\n",
        "   x   = K.abs(y_true - y_pred)\n",
        "   x   = K.switch(x < HUBER_DELTA, 0.5 * x ** 2, HUBER_DELTA * (x - 0.5 * HUBER_DELTA))\n",
        "   return  K.sum(x)\n",
        "  \n",
        "  \n",
        "#epoch number\n",
        "epo = 450\n",
        "# define optimizer\n",
        "adam = optimizers.Adam(lr=0.001, decay=0.7)\n",
        "# compile classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=[smoothL1, 'mean_squared_error'],\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x = [train_points, train_intermediate], y= [train_labels, train_classes], batch_size=32, epochs=epo, validation_data=([dev_points,dev_intermediate], [dev_labels, dev_classes]), shuffle=True, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:3170: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/450\n",
            "4000/4000 [==============================] - 37s 9ms/step - loss: 2223.1518 - dense_10_loss: 2223.0425 - dense_11_loss: 0.1098 - dense_10_accuracy: 0.1262 - dense_11_accuracy: 0.8170 - val_loss: 2086.5570 - val_dense_10_loss: 2048.2686 - val_dense_11_loss: 0.0933 - val_dense_10_accuracy: 0.2830 - val_dense_11_accuracy: 0.8280\n",
            "Epoch 2/450\n",
            "4000/4000 [==============================] - 30s 8ms/step - loss: 2123.8620 - dense_10_loss: 2123.7642 - dense_11_loss: 0.0977 - dense_10_accuracy: 0.1190 - dense_11_accuracy: 0.8170 - val_loss: 2060.7110 - val_dense_10_loss: 2023.5381 - val_dense_11_loss: 0.0967 - val_dense_10_accuracy: 0.1920 - val_dense_11_accuracy: 0.8280\n",
            "Epoch 3/450\n",
            "4000/4000 [==============================] - 31s 8ms/step - loss: 2070.0148 - dense_10_loss: 2069.9165 - dense_11_loss: 0.0981 - dense_10_accuracy: 0.1447 - dense_11_accuracy: 0.8170 - val_loss: 2026.3796 - val_dense_10_loss: 1990.1135 - val_dense_11_loss: 0.0908 - val_dense_10_accuracy: 0.0170 - val_dense_11_accuracy: 0.8280\n",
            "Epoch 4/450\n",
            "4000/4000 [==============================] - 31s 8ms/step - loss: 2054.0779 - dense_10_loss: 2053.9829 - dense_11_loss: 0.0953 - dense_10_accuracy: 0.1375 - dense_11_accuracy: 0.8170 - val_loss: 2031.8458 - val_dense_10_loss: 1994.7289 - val_dense_11_loss: 0.0890 - val_dense_10_accuracy: 0.0400 - val_dense_11_accuracy: 0.8280\n",
            "Epoch 5/450\n",
            "4000/4000 [==============================] - 31s 8ms/step - loss: 2046.0449 - dense_10_loss: 2045.9525 - dense_11_loss: 0.0922 - dense_10_accuracy: 0.1030 - dense_11_accuracy: 0.8170 - val_loss: 2043.9223 - val_dense_10_loss: 2006.6769 - val_dense_11_loss: 0.0874 - val_dense_10_accuracy: 0.1640 - val_dense_11_accuracy: 0.8280\n",
            "Epoch 6/450\n",
            "4000/4000 [==============================] - 31s 8ms/step - loss: 2005.6347 - dense_10_loss: 2005.5457 - dense_11_loss: 0.0896 - dense_10_accuracy: 0.1243 - dense_11_accuracy: 0.8250 - val_loss: 2004.3630 - val_dense_10_loss: 1968.0400 - val_dense_11_loss: 0.0821 - val_dense_10_accuracy: 0.1310 - val_dense_11_accuracy: 0.8280\n",
            "Epoch 7/450\n",
            " 832/4000 [=====>........................] - ETA: 22s - loss: 1902.8731 - dense_10_loss: 1902.7847 - dense_11_loss: 0.0887 - dense_10_accuracy: 0.1334 - dense_11_accuracy: 0.8462"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pyathnROB7ib"
      },
      "source": [
        "#model.save('/drive/Colab Notebook/current_model')\n",
        "import pickle\n",
        "\n",
        "with open('drive/Colab Notebooks/trainHistoryDict_history450', 'wb') as file_pi:\n",
        "     pickle.dump(history.history, file_pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HWwRJbvdKI18"
      },
      "source": [
        "model.save_weights('drive/Colab Notebooks/my_model_weights_450.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTrB3Dvf8USk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623a36c3-40d9-4c8c-9e7d-244820e2e6e5"
      },
      "source": [
        "# Evaluating the model on the test data    \n",
        "loss = model.evaluate([test_points, test_intermediate], [test_labels, test_classes], verbose=0)\n",
        "print('Test Loss:', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: [880.5594246500448, 868.686279296875, 0.059154532849788666, 0.23940148949623108, 0.8977556228637695]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0xopLNDeePq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9145b1-c389-43ee-8495-dddf616b372c"
      },
      "source": [
        "#Evaluating model of Dev Set\n",
        "loss = model.evaluate([dev_points, dev_intermediate], [dev_labels, dev_classes], verbose=0)\n",
        "print('Dev Loss:', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev Loss: [836.7958598632813, 820.1350708007812, 0.06046322360634804, 0.23800000548362732, 0.8939999938011169]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}